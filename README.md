# APITextIndexer
Приложение сканирует указанную папку и подпапки, находит текстовые файлы и индексирует их. После чего запускается API-сервер, выдающий по HTTP запросам статистику по словам и файлам.  

### Возможности
 - поддерживает русский и английский языки
 - сканирует txt, md, docx файлов на выбор
 - обрабатывает также текстовые файлы с кодировками отличными от UTF-8
 - пропускает файлы, если их содержимое не текстовое, даже если расширение говорит об обратном

### Установка
Для работы приложения необходимо установить следующие пакеты:<br>
`pip install argparse pymongo flask_restful chardet`<br>
либо установить зависимости из файла requirements.txt:<br>
`pip install -r requirements.txt`

### Запуск
`python run.py`<br>
По умолчанию приложение сканирует текующую директорию со всеми поддиректориями и ищет файлы c расширением `txt`<br>
Для задания другой директории укажите ее с ключом `-d`. Наличие слэша на конце не имеет значения:<br>
`python run.py -d /library/`<br>
Чтобы укзаать нужные для индексации типы файлов, перечислите их расширения в ключе `-t`:<br>
`python run.py -d /library/ -t txt docx`<br>
Поддерживаются типы `txt`, `md` и `docx`. Без ключа индексируются только `txt` файлы.

## Описание запросов и результатов выдачи API
### Статистика по всем файлам
`/files/` - список всех файлов и общей статистикой по ним. Результаты:<br>
`max_size` - максимальный размер файла<br>
`min_size`  - минимальный разме рфайла<br>
`avg_size` - средний размер файла<br>
`max_total_words` - максимальное кол-во слов в одном файле<br>
`min_total_words`  - минимальное кол-во слов в одном файле<br>
`avg_total_words` - среднее кол-во слов в файлах<br>
`max_uniq_words` - максимальное кол-во уникальных слов в одном файле<br>
`min_uniq_words`  - минимальное кол-во уникальных слов в одном файле<br>
`avg_uniq_words`  - среднее кол-во уникальных слов в одном файле<br>
`count_files`  - кол-во файлов<br>
`list_files` - список всех файлов, где `_id` - уникальный идентификатор, `path_file` - полный путь к файлу

### Статистика по файлу
`/files/{id}` - статистика по файлу с уникальным идентификатором `id`. Результаты:<br>
`_id` - уникальный идентификатор<br>
`name` - имя файла<br>
`path` - путь к файлу<br>
`ext` - расширение файла<br>
`size` - размер файла в байтах<br>
`total_words` - общее кол-во слов в файле<br>
`frequent_word` - самое частое слово в файле, словарь где `word` - слово, `count` - кол-во вхождений слова<br>
`rare_word` - самое редкое слово в файле, словарь где `word` - слово, `count` - кол-во вхождений слова<br>
`avglen_word` - средняя длина слова в файле среди всех слов<br>
`avglen_uniqword` - средняя длина слова в файле среди уникальных слов<br>
`vowel_count` - количество гласных букв в файле<br>
`consonant_count` - количество согласных букв в файле<br>
`vowel_count_uniqword`  - количество гласных букв в файле среди уникальных слов<br>
`consonant_count_uniqword`  - количество согласных букв в файле среди уникальных слов<br>

### Статистика по всем словам
`/words/` - общая статистика по словам. Результаты:<br>
`total_words` - общее кол-во слов во всех файлах<br>
`uniq_words` - кол-во уникальных слов во всех файлах<br>
`avglen_word` - средняя длина слова во всех файлах<br>
`avglen_uniqword` - средняя длина уникальных слов во всех файлах<br>
`vowel_count` - кол-во гласных во всех словах всех файлов<br>
`cons_count` - кол-во согласных во всех словах всех файлов<br>
`vowel_count_uniqword` - кол-во гласных во всех уникальных словах всех файлов<br>
`cons_count_uniqword` - кол-во согласных во всех уникальных словах всех файлов<br>
`rare_word` - самое редкое слово во всех файлах, словарь, возвращающий немного более краткий вариант объекта слово (см.ниже)<br>
`frequent_word` - самое частое слово во всех файлах, аналогично `rare_word`

### Статистика по слову
Есть два варианта получения статистики по слову: по id и по текстовому представлению.<br>
`/words/{id}` - статистика по слову с уникальным идентификатором `id`. Например:<br>
`/words/5e29eca6c57cbcaeeba1e74b`<br>
`/words/text/{word}` - статистика по слову с текстовым представлением. Например:<br>
`/words/text/привет`<br>
Результат не зависит от типа запроса.<br>
`_id` - уникальный идентификатор слова<br>
`word` - текстовое представление слова<br>
`count` - кол-во вхождений слова во всех файлах<br>
`len` - длина слова<br>
`vowel` - кол-во гласных в слове<br>
`consonant` - кол-во согласных в слове<br>
`files_stat` - список объектов файлов краткого формата, где нашлось это слово. Состоит из словарей, где `_id` - уникальный идентификатор файла,  `name` - путь к файлу с именем и  `count` - количество вхождений данного слова в этом файле.

## Описание реализации
Приложение разделено на 2 части. `folderparser.py` перебирает файлы, проверяет, обрабатывает если нужно, вычленяет слова, собирает их все в один большой словарь и вставляет в MongoDB. Каждое уникальное слово - документ в коллекции. `responces.py` отвечает за выдачу результатов через API. Статистика по каждому ресурсу собирается через запросы к БД и выдается пользователю API. Для удобного добавления новых форматов для индексации, функции чтения и предварительной обработки файлов были вынесены в отдельный модуль `IOfile.py`. Собирает весь функционал и является точкой входа `run.py`